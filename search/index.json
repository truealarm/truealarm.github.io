[{"content":"mutex(Mutual execlusion)은 다수의 프로세스나 스레드가 공유하는 자원을 안전하게 사용(concurrent control)할 수 있도록 해주는 기술입니다. 상호 배제라는 직역의 의미대로 한 스레드가 이미 임계 영역에 진입했다면 다른 스레드가 임계 영역에 진입하지 못하도록 막아줍니다. mutex의 원리나 필요성을 제대로 이해하지 않고 멀티스레드 프로그래밍을 한다면, Race condition 같은 문제를 초래합니다.\nRace condition 여러 스레드가 공유 데이터에 접근하는 임계 영역을 제한하지 않을 때 발생하는 Race condition 문제의 예시는 다음과 같습니다. 아래 그림처럼 i-1, i, i+1, i+2 노드가 연결된 싱글 리스트에서 i 노드를 삭제하려면, i-1 노드의 next 주소를 i+1 주소로 변경하는 코드를 통해 i 노드를 제거합니다. 문제는 2개의 쓰레드가 각각 i 노드와 i+1 노드를 동시에 삭제를 시도하면, 예상과 달리 i+1 노드가 삭제되지 않는 결과가 나타납니다. 이런 결과가 발생한 이유는 첫 번째 스레드가 노드를 완전히 삭제하기 전에, 두 번째 스레드도 삭제를 시도하였고, 스레드 간의 어떠한 협의나 규약 없이 임계 영역의 삭제 코드를 실행해서 그렇습니다.\nRace condition 문제가 무서운 이유는 잘못된 concurrent operation을 수행하는 코드로 인해 뜻밖의 코드에서 런타임 에러가 발생하거나, 오히려 런타임 에러 없이 정상적으로 종료돼 문제가 발생한 사실조차 알아차리기 힘들기 때문입니다. 게다가 Race condition은 크리티컬한 취약점으로 귀결될 가능성이 높습니다. 보통 웹 백엔드 서버의 경우 쿠폰 중복 사용, 이중 출금 등 금전적인 손해를 유발하는 취약점이 있고, 네이티브한 프로그램에서는 경계 검사 우회, UAF와 같은 취약점으로 이어져 메모리 보호 기법을 우회하는 발판을 제공합니다.\n개인적으로 골치 아프다고 생각했던 이유는 그날의 운에 따라 Race condition이 발생할 수도 있고 안할 수도 있다는 특징 때문입니다. Race condition은 2개 이상의 스레드가 동시에 임계 영역에 접근할 때 발생하는 문제여서, 운이 좋게 각각의 스레드가 임계 영역을 차례대로 실행한다면 아무런 문제가 발생하지 않습니다. 스레드의 실행 순서와 선점(preemption)은 운영체제에서 스케쥴링하고, CPU 코어 수나 스레드 우선 순위, I/O 블록 여부에 따라 순서가 크게 달라지므로 그야말로 복불복입니다. (물론 모든게 알고리즘에 의해 결정되므로 엄밀히 따지면 복불복은 아니지만, 애플리케이션 레벨에서는 제멋대로 실행되는 것처럼 보입니다)\nRace condition을 악용하려는 공격자는 보통 단 시간내 최대한 많은 쓰레드가 임계 영역에 접근하도록 유도하여 고의적으로 문제를 유발시킵니다. 이런 이유로 기능 테스크 코드만으로는 Race condition을 발견하기 힘들고, 실제 서비스가 프로덕션으로 배포되고 사용자가 충분히 많아진 시점에서 발견되곤 합니다.\nMutual Exclusion mutex의 공유 자원 관리는 총 4가지 상태로 나누어 진행할 수 있는데, 임계 영역으로 진입을 시도하는 Trying 상태, 임계 영역에 진입한 Critical 상태, 임계 영역의 실행이 끝나 다른 스레드에게 차례를 넘겨주는 Exit 단계, 마지막으로 임계 영역 이외의 공유 자원에 접근하지 않는 Remainder 상태입니다. 노드를 삭제하는 코드 영역을 임계 영역으로 설정하고, 다음과 같은 과정을 통해 임계 영역에 하나의 스레드만 진입하게 할 수 있습니다.\n스레드가 노드를 삭제하는 코드(임계 영역)에 도달하면 Remainder 상태에서 Trying 상태로 전환합니다. 임계 영역에 진입한 스레드가 없으면 Critical 상태로 전환하고 있으면 대기합니다. 이때 임계 영역에 진입한 스레드가 있는지 확인하고, 진입하는 모든 작업 중간에 다른 스레드가 선점하지 못하도록 막아야 합니다. Critical 상태의 스레드가 노드를 완벽히 삭제한 후 Exit 상태로 전환하여, 다른 스레드가 임계 영역을 실행할 수 있도록 합니다. 삭제를 끝낸 스레드는 Reminder 상태로 돌아가 임계 영역 이외의 코드를 실행합니다. Deadlock Freedom mutex를 적용했을 때 보장되어야 하는 특성 중 임계 영역에서 스레드를 상호 배제시켜 주는 mutual exclusion 이외의 중요한 특성이 하나 더 있습니다. 스레드들이 Trying 상태에 계속 머물러, 아무도 임계 영역의 코드를 실행할 수 없어 진전이 없는 교착 상태(Deadlock)가 발생하지 않도록 보장해야 합니다. 한 스레드가 Trying 상태에서 무한히 기다리고 있다면, 어떤 스레드는 임계 영역에 이미 진입한 상태임을 항상 보장하는 특성이 Deadlock Freedom입니다.\n그렇다면 위와 같이 각각의 스레드가 2개의 mutex를 사용하는 경우를 생각해봅시다. 1,2번 스레드가 각각 1,2번 임계 영역에 진입한 후에 다른 임계 영역으로 진입을 시도한다면, 이미 서로 진입했던 임계 영역이라 무한 루프에 빠지게 됩니다. 놀랍게도 위 상황처럼 임계 영역에 진입한 스레드가 무한 루프에 빠지거나, 모종의 이유로 Exit 상태로 전환되지 않아 모든 스레드가 영원히 대기하더라도 Deadlock Freedom은 만족하는 겁니다. 1,2번 스레드 모두 아무런 진전이 없는 Deadlock 상태처럼 보이지만, 이미 Trying 상태를 벗어나 1,2번 임계 영역에 진입한 이후입니다. 따라서 무한 루프를 발생시키는 코드라 할 지라도 임계 영역의 코드를 실행하고 있으므로 진전이 있다고 말합니다.\nLockout Freedom Deadlock Freedom을 만족하더라도 우선 순위가 높은 스레드가 임계 영역에 반복적으로 여러번 접근하면 독점 현상이 발생할테니, 우선 순위가 낮은 스레드는 계속 Trying 상태로 머무르는 기아 상태(Starvation)에 빠질 수 있습니다. Deadlock Freedom에서 확장되어 임계 영역에 진입하고자 하는 Trying 상태의 스레드가 유한한 시간 내에 임계 영역에 진입하여 기아 상태가 발생하지 않도록 보장하는 특성을 Lockout Freedom이라고 부릅니다. Lockout Freedom은 mutex의 필수 특성은 아닙니다.\nHardware implemenation 하드웨어 기반으로 mutex를 구현하는 방법 중 가장 간단한 방법은 임계 영역에 진입하기 전에 interrupt를 비활성화해 cpu가 context swithch을 하지 못하게 만드는 것입니다. interrupt가 발생하지 않으면 스레드나 프로세스의 실행이 스케쥴링되지 않으므로, 임계 영역 실행 도중에 다른 스레드가 선점하지 못하게 막을 수 있지만 Uniprocesser에서만 가능합니다. Multiprocessor는 각각의 cpu가 병렬적으로 실행되므로, interrupt가 비활성화되지 않은 다른 cpu가 임계 영역에 진입할 수 있습니다. 물론 모든 프로세서의 interrupt를 비활성화하면 되지만, 다른 프로세스의 interrupt 설정까지 변경하기 힘들고 성능이 매우 저하되므로 비싼 multiprocessor를 사놓고 할 짓은 아닙니다. 게다가 임계 영역에 머무르는 동안 interrupt를 비활성화하면 시간 정보(system clock)을 가져오지 못하거나, 임계 영역에서 다시 interrupt 설정을 복구하지 못하고 종료되면 전체 시스템의 장애로 이어지는 단점이 있습니다.\n1 2 3 4 5 function TestAndSet(boolean_ref lock) { boolean initial = lock; lock = true; return initial; } 이런 한계점을 극복하기 위해 공유 메모리와 read-modify-write 명령어를 통해 Busy-waiting 시스템을 구현합니다. read-modify-write 명령어에 속하는 test-and-set 명령어는 위 코드와 같이 스레드가 공유하는 메모리에서 초기 lock 상태를 읽어온 뒤, lock 상태를 true로 설정하고 초기 lock 상태를 반환하는 기능을 수행합니다. 당연히 하드웨어에서 이 모든 작업을 atomic하게 수행할 수 있는 단일 어셈블리를 지원해야 합니다. 명령어의 반환 값이 false면 임계 영역에 진입하고, true면 다른 작업을 수행하거나 루프를 돌며 차례를 기다리는 방식으로 mutex를 구현할 수 있습니다. 이 과정을 코드로 표현하면 아래와 같습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 while true do: // state: Remainder ... do remainder stuff ... // state: Trying while TestAndSet(lock) = true { /* spin */ } // state: Critical ... do critical section stuff ... // state: Exiting reset(lock) 공유 메모리로 생성한 lock의 상태를 읽고, 변경하는 과정을 모두 atomic하게 수행하므로 임계 영역에 항상 하나의 스레드만 진입하는 것을 보장할 수 있습니다. 추가적으로 임계 영역에 진입하기 위해 루프를 돌며 차례를 기다리는 방식을 spinlock이라고 부릅니다. 다른 스레드로 context switch하고, 나중에 다시 context를 restore 하는 과정을 거치지 않고, 짧은 시간동안 차례를 기다려 오버헤드를 최소화합니다.\n위 방식은 mutex의 기본 조건은 모두 만족하지만, lockout freedom은 만족하지 않습니다. 그래서 만약 특정 스레드가 빠르게 lock을 set하고 reset하는 과정을 반복한다면, 다른 스레드는 임계 영역에 진입하지 못하게 되는 starvation이 발생하고, 이로 인해 몇몇 스레드의 성능이 비정상적으로 떨어질 수 있습니다.\n이를 해결하려면 스레드의 도착 순서를 기록하면 되고, atomic queue를 통해 1) Trying 시점에 스레드 id를 enquque, 2) queue의 head 값과 본인의 스레드 id가 일치할 때 임계 영역에 진입, 3) Exiting 시점에 dequeue하면 됩니다. atomic queue를 사용하는 이유는 enqueue, dequeue 할 때 race condition이 발생하지 않게 하기 위함입니다. (atmoic queue는 mutex와 달리 lock에 의존적이지 않도록 compare-and-swap 명령어를 통해 Non-blocking 자료구조로 구현합니다)\nSoftware implemenation test-and-set 명령어와 같이 하드웨어가 제공하는 atomic operation 없이 소프트웨어 구현으로만 mutex를 구현할 수 있는 여러 알고리즘이 존재합니다. 알고리즘에 들어간 아이디어가 궁금하여 Dekker\u0026rsquo;s algorithm과 Lamport\u0026rsquo;s bakery algorithm을 살펴보았습니다. 다만, 소프트웨어 알고리즘은 cpu 최적화 기법 중 Out-of-order execution이 적용되면 의도한 순서대로 순차적으로 명령어가 실행되지 않기에 문제가 발생할 수 있지만, Memory ordering을 적용하여 해결할 수 있습니다.\nDekker\u0026rsquo;s algorithm Dekker\u0026rsquo;s algorithms은 2개의 프로세스가 임계 영역에 동시에 접근해도 상호 베타적으로 실행되도록 보장하는 최초의 mutual execlusion 알고리즘입니다. 프로세스는 임계 영역에 들어가겠다는 의도를 표현할 플레그 값(will_enter)과, 임계 영역에 진입 가능한 프로세스를 나타나는 플레그 값(turn)을 공유하는게 특징입니다. Dekker\u0026rsquo;s algorithms을 슈도 코드로 구현해가며, 어떤 아이디어가 적용됐는지 살펴보겠습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /* Mutex version 1 ** global variables: P0_enter, P1_enter */ Process 0: /* State: Trying */ while P1_enter = true { /* spin */ } // [A] P0_enter ← true /* State: Critical */ ... do critical section stuff ... /* State: Exiting */ P0_enter ← false 위 코드는 첫 번째 프로세스(P0)가 사용하는 코드로, 임계 영역에 도달하면 P1_enter 값을 읽어 상대 프로세스가 임계 영역에 이미 진입했는지 확인합니다. 만약 없다면 곧바로 임계 영역으로 진입하고 P0_enter을 true로 설정하여 임계 영역에 진입했음을 알립니다. 임계 영역을 나가기 직전에 P0_enter 값을 다시 false로 설정하여 P1에게 차례를 내줍니다.\n하지만 [A] 지점에서 P0_enter 값을 true로 설정하는 코드가 실행되기 전에 context switch가 발생하여 P1이 선점한다면, 임계 영역에 2개의 프로세스 모두 진입하게 되는 race condition이 발생합니다. 이를 막기 위해 P0_enter 의 설정 시점을 아래와 같이 변경합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /* Mutex version 2 ** global variables: P0_will_enter, P1_will_enter */ Process 0: /* State: Trying */ P0_will_enter ← true // [A] while P1_will_enter = true { /* spin */ } /* State: Critical */ ... do critical section stuff ... /* State: Exiting */ P0_will_enter ← false 이제는 P0 프로세스가 임계 영역에 진입할 것이라는 의도를 나타내는P0_will_enter 값에 true를 설정하고, P1_will_enter 값을 확인하여 P1 프로세스가 임계 영역에 진입했는지 확인합니다. 덕분에 두 개의 프로세스가 동시에 임계 영역에 접근할 가능성은 없어졌지만, [A] 지점에서 context switch가 발생하면 P0_will_enter, P1_will_enter 모두 true가 될 수 있어 아무도 임계 영역에 진입하지 못하는 교착 상태에 빠집니다. 이는 mutex의 기본 조건인 deadlock freedom에 위배되는 구현입니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* Mutex version 3 ** global variables: P0_will_enter, P1_will_enter, priority */ Process 0: /* State: Trying */ P0_will_enter ← true while P1_will_enter = true { P0_will_enter ← false while priority != P0 { /* spin */ } P0_will_enter ← true } /* State: Critical */ ... do critical section stuff ... /* State: Exiting */ priority ← P1 P0_will_enter ← false deadlock 문제를 해결하기 위해 어떤 프로세스가 먼저 실행할 지 결정할 priority 값을 추가합니다. 만약 P0_will_enter, P1_will_enter 모두 true가 되어 두 개의 프로세스가 모두 while 문으로 진입하였더라도, 본인의 순서가 아니면 will_enter 값을 false로 설정하고 차례를 기다립니다. 따라서 하나의 프로세스는 while 문 밖으로 빠져나와 임계 영역을 진입하게 됩니다.\n여기까지 구현했다면 mutex로 사용하기 충분하지만, starvation으로부터 자유롭지 않으므로 공정성(fairness)을 높이기 위한 조치를 취할 수 있습니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /* Mutex version 4 ** global variables: P0_will_enter, P1_will_enter, priority */ Process 0: /* State: Trying */ P0_will_enter ← true while P1_will_enter = true { if priority != P0 { P0_will_enter ← false while priority != P0 { /* spin */ } P0_will_enter ← true } } /* State: Critical */ ... do critical section stuff ... /* State: Exiting */ priority ← P1 P0_will_enter ← false 첫 번째 while 문에서 priority 값을 비교해 본인의 순서인지 확인하고, 본인의 순서라도 deadlock에 빠지지 않기 위해 다른 프로세스가 will_enter를 false를 설정하는 것을 기다립니다. 안쪽의 while 문은 본인의 순서가 아닌 상태에서 다른 프로세스가 임계 영역에서 빠져나가는 것을 기다리는 루프입니다. 이렇게 현재 priority에 따라 목적에 맞는 spin을 선택하도록 하면 공정성을 좀 더 높일 수 있습니다. 위처럼 mutual exclusion, deadlock freedom, starvation freedom까지 고려한 알고리즘이 바로 Dekker\u0026rsquo;s algorithm입니다.\nLamport\u0026rsquo;s bakery algorithm Dekker\u0026rsquo;s algorithm은 2개의 프로세스가 임계 영역에 접근하는 경우만 고려하였기 때문에, 수십개 이상의 프로세스와 스레드가 동시에 실행되는 상황에서 적용하기 힘듭니다. 반면에 Lamport\u0026rsquo;s bakery algorithm은 2개 이상의 스레드가 동시에 실행되는 환경에서도, 완벽하게 임계 영역에 진입할 스레드를 결정하여 동시성 프로그래밍을 가능하게 합니다.\nLamport\u0026rsquo;s bakery algorithm이 상호 배제를 위해 채택한 방식은 실생활의 번호표 대기 시스템과 비슷합니다. 은행에서 동시간대 몰린 고객들을 관리할 때 입구에서 고객마다 번호표를 뽑도록 하고, 대기실 모니터에 현재 상담 중인 번호를 알려줍니다. 상담이 끝나 고객이 창구를 나가면, 현재 번호에 1을 더하고 대기하던 고객들은 모두 자신의 번호표에 적힌 번호를 통해 차례를 확인하여 일치하면 상담 창구로 들어갑니다. 여기서 고객을 하나의 스레드로 생각하고 알고리즘을 구현하면 됩니다.\n하지만 컴퓨터 세계에서 모든 스레드가 사이좋게 중복되지 않은 번호표를 뽑는 것을 기대할 수 없습니다. 만약 여러 스레드가 중복되지 않은 번호표를 뽑는게 가능하다면, Lamport\u0026rsquo;s bakery algorithm을 통해 해결하고자 하는 상호 배제 문제를 해결할 필요가 없습니다. 왜냐하면 여러 개의 스레드가 동시에 번호표를 발급받는 상황에서 atomic operation이나 mutex를 통해 동시성 프로그래밍을 하지 않으면, 같은 번호를 발급받게 되는 상황이 생길 수 있기 때문입니다. 그래서 Lamport\u0026rsquo;s bakery algorithm은 프로세스가 같은 번호표를 뽑는 상황에 대비하여 스레드마다 갖는 고유한 아이디를 활용합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /* Mutex version 1 global variables: Number[1..NUM_THREADS] = {0}; */ lock(int i) { Number[i] = 1 + max(Number[1], ..., Number[NUM_THREADS]); // [A] for (int j = 1; j \u0026lt;= NUM_THREADS; j++) { // Wait until all threads with smaller numbers or with the same // number, but with higher priority, finish their work: while ((Number[j] != 0) \u0026amp;\u0026amp; ((Number[j], j) \u0026lt; (Number[i], i))) { /* spin */ } // [B] } } unlock(int i) { Number[i] = 0; } Thread(int i) { while (true) { lock(i); ... do critical section stuff ... unlock(i); // non-critical section... } } 위 코드가 지금까지 설명한 내용을 토대로 Lamport\u0026rsquo;s bakery algorithm를 구현한 코드입니다. lock 함수는 스레드가 번호표를 뽑고 [A], 자신의 번호를 계속 확인하다 차례가 오면 [B], 임계 영역에 진입하는 함수이고, unlock 함수는 임계 영역에서 빠져나올 때 실행하는 함수입니다.\n1 while ((Number[j] != 0) \u0026amp;\u0026amp; ((Number[j], j) \u0026lt; (Number[i], i))) { /* spin */ } lock 함수에서 두 번째 while 문을 통해 실행하는 위 코드가 어떤 스레드가 임계 영역에 들어갈 차례인지 결정하는 코드인 동시에 모두가 차례대로 임계 영역에 접근하기 위해 따르는 규칙입니다. Number 배열은 모든 스레드가 공유하는 변수이며 스레드 아이디를 인덱스로 사용하여 스레드가 발급받은 번호를 저장합니다. 전체 스레드 갯수만큼 반복문을 돌며, 다른 스레드의 번호가 내 번호보다 작은지 비교합니다. 작다면 해당 스레드가 먼저 번호표를 뽑은 스레드이므로 spin을 돌며 기다립니다. 번호표를 뽑은 스레드 중 가장 작은 번호의 스레드가 임계 영역을 실행하고 나가면서 unlock 함수를 호출하므로, 다음으로 작은 번호표를 뽑은 스레드가 spin에서 빠져나와 임계 영역으로 진입합니다.\n처음에 설명한대로 서로 다른 스레드가 동시에 [A] 지점의 코드를 실행하면, 같은 번호를 갖는 경우가 생길 수 있어 번호가 같은 경우도 대비해야 합니다. 그래서 Number 정보가 같은 경우, 스레드마다 고유한 아이디인 i, j를 비교하여 더 작은 아이디의 스레드가 임계 영역에 진입합니다. 이제 더이상 고려해야 하는 문제가 없어보이지만, 해당 구현에는 큰 결함이 하나 존재합니다.\n만약 어떤 스레드가 [A]에서 최대값을 Number[i]에 저장하기 직전에 context switching이 발생한다면, 다른 스레드가 [B]에서 Number 값을 제대로 비교할 때 이를 확인할 방법이 없습니다. (최대값을 계산하고 저장하는 코드는 atomic하게 실행되지 않으므로 이런 상황이 발생할 수 있습니다) 이게 문제가 될 수 있는 상황은 다음과 같습니다. 1번 스레드가 Number[1]에 번호를 저장하기 직전에 2번 스레드가 선점한다면 1,2번 스레드는 같은 번호를 가지게 됩니다. 이후로 2번 스레드는 1번 스레드가 아직 Number[1]에 번호를 저장하지 않은 사실은 모른채, while문을 통해 모든 스레드의 번호를 확인하고 본인의 번호가 가장 작은걸 확인하고 임계 영역으로 진입합니다. 이때 1번 스레드가 다시 실행되어 Number[1]에 번호를 저장하고 while문을 통해 모든 스레드의 번호를 확인하지만, 2번 스레드보다 본인의 아이디가 더 작은걸 확인하고 임계 영역에 진입합니다. 결국 2개의 스레드가 모두 임계 영역에 들어가는 사태가 발생합니다.\nLamport\u0026rsquo;s bakery algorithm에서는 이런 문제를 해결하려고 임계 영역에 진입하려는 스레드가 번호를 완전히 저장했는지 확인할 목적으로 Entering 변수를 추가합니다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /* Mutex version 2 global variables: Entering[1..NUM_THREADS] = {false}; Number[1..NUM_THREADS] = {0}; */ lock(int i) { Entering[i] = true; Number[i] = 1 + max(Number[1], ..., Number[NUM_THREADS]); Entering[i] = false; for (int j = 1; j \u0026lt;= NUM_THREADS; j++) { // Wait until thread j receives its number: while (Entering[j]) { /* wait */ } // [C] // Wait until all threads with smaller numbers or with the same // number, but with higher priority, finish their work: while ((Number[j] != 0) \u0026amp;\u0026amp; ((Number[j], j) \u0026lt; (Number[i], i))) { /* spin */ } // [D] } } unlock(int i) { Number[i] = 0; } Thread(int i) { while (true) { lock(i); ... do critical section stuff ... unlock(i); // non-critical section... } } Number[i]를 저장하기 전에 Entering[i]에 true를, 저장이 완료되면 false를 설정하는 코드랑 Entering[j]가 false가 될 때까지 기다리는 [C] 코드가 추가됐습니다. [C]에 추가된 반복문이 Entering[j]가 false가 될 때까지 기다리므로, [D]에서 다른 스레드의 번호를 비교하는 시점에는 Number에 값을 저장하지 않은 스레드를 걱정하지 않아도 됩니다.\n이렇게 구현한 Lamport\u0026rsquo;s bakery algorithm은 Dekker\u0026rsquo;s algorithm과 마찬가지로 mutual exclusion, deadlock freedom, lockout freedom을 만족합니다. 게다가 모든 스레드는 먼저 온 순서대로 번호를 부여받고, 임계 영역에 진입하므로 높은 fairness를 갖는 알고리즘입니다.\nReferences https://en.wikipedia.org/wiki/Mutual_exclusion https://www.cs.yale.edu/homes/aspnes/pinewiki/MutualExclusion.html http://www.qnx.com/developers/docs/6.3.2/neutrino/prog/overview.html https://helix979.github.io/jkoo/post/os-scheduler/ https://lamport.azurewebsites.net/pubs/mutual2.pdf ","date":"2022-11-20T03:54:03+09:00","image":"https://truealarm.github.io/p/mutex-in-a-nutshell/cover_hud8944986dce5db4c38161ba4174c77f6_30571_120x120_fill_box_smart1_3.png","permalink":"https://truealarm.github.io/p/mutex-in-a-nutshell/","title":"Mutex in a nutshell"}]